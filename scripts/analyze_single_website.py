"""
å•ä¸ªç½‘ç«™æ·±åº¦åˆ†æå·¥å…·
åˆ†ææŒ‡å®šç½‘ç«™ï¼Œæå–çœŸå®DOMé€‰æ‹©å™¨ï¼ŒéªŒè¯å…ƒç´ æå–
"""
import asyncio
import json
from pathlib import Path
from playwright.async_api import async_playwright
from typing import Dict, List, Any, Optional


async def analyze_single_website(
    name: str,
    url: str,
    zipcode: Optional[str] = None,
    output_dir: Path = None
) -> Dict[str, Any]:
    """
    æ·±åº¦åˆ†æå•ä¸ªç½‘ç«™
    
    Args:
        name: ç½‘ç«™åç§°
        url: ç½‘ç«™URL
        zipcode: é‚®æ”¿ç¼–ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«æ‰¾åˆ°çš„é€‰æ‹©å™¨å’Œæå–çš„æ•°æ®
    """
    if output_dir is None:
        output_dir = Path(__file__).parent.parent / "analysis_output"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*70}")
    print(f"æ·±åº¦åˆ†æ: {name}")
    print(f"URL: {url}")
    if zipcode:
        print(f"Zipcode: {zipcode}")
    print(f"{'='*70}\n")
    
    result = {
        'name': name,
        'url': url,
        'zipcode': zipcode,
        'article_selector': None,
        'title_selector': None,
        'link_selector': None,
        'date_selector': None,
        'summary_selector': None,
        'extracted_data': [],
        'has_cloudflare': False,
        'needs_special_handling': []
    }
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        )
        page = await context.new_page()
        
        try:
            # è®¿é—®ç½‘ç«™
            print(f"ğŸ“ è®¿é—®ç½‘ç«™: {url}")
            try:
                # å…ˆå°è¯•domcontentloadedï¼ˆæœ€å¿«ï¼‰
                await page.goto(url, wait_until="domcontentloaded", timeout=90000)
                print("  âœ“ é¡µé¢DOMå·²åŠ è½½")
            except Exception as e1:
                print(f"  âš  domcontentloadedè¶…æ—¶ï¼Œå°è¯•load: {str(e1)[:50]}")
                try:
                    await page.goto(url, wait_until="load", timeout=90000)
                    print("  âœ“ é¡µé¢å·²åŠ è½½")
                except Exception as e2:
                    print(f"  âš  loadè¶…æ—¶ï¼Œå°è¯•commit: {str(e2)[:50]}")
                    try:
                        await page.goto(url, wait_until="commit", timeout=90000)
                        print("  âœ“ é¡µé¢å¯¼èˆªå·²æäº¤")
                    except Exception as e3:
                        print(f"  âŒ æ‰€æœ‰åŠ è½½ç­–ç•¥éƒ½å¤±è´¥: {str(e3)[:50]}")
                        raise
            
            # ç­‰å¾…JavaScriptæ‰§è¡Œå’Œå†…å®¹åŠ è½½
            print("  â³ ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½...")
            await asyncio.sleep(10)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œè®©åŠ¨æ€å†…å®¹åŠ è½½
            
            # å¤„ç†å¼¹çª—
            print("ğŸ” æ£€æŸ¥å¼¹çª—...")
            close_selectors = [
                "button[aria-label*='close' i]",
                "button[aria-label*='Close' i]",
                ".close-button",
                "[data-testid='close']",
                ".modal-close",
                ".popup-close",
                ".cookie-consent button",
                "#onetrust-accept-btn-handler"
            ]
            for selector in close_selectors:
                try:
                    close_btn = await page.query_selector(selector)
                    if close_btn and await close_btn.is_visible():
                        await close_btn.click(timeout=2000)
                        print(f"  âœ“ å…³é—­å¼¹çª—: {selector}")
                        await asyncio.sleep(2)
                        break
                except:
                    continue
            
            # æ£€æŸ¥Cloudflare
            print("ğŸ›¡ï¸  æ£€æŸ¥åçˆ¬è™«æœºåˆ¶...")
            cf_selectors = [
                "#challenge-form",
                ".cf-browser-verification",
                "#cf-wrapper",
                ".cf-im-under-attack"
            ]
            for selector in cf_selectors:
                if await page.query_selector(selector):
                    result['has_cloudflare'] = True
                    print(f"  âš  æ£€æµ‹åˆ°Cloudflare: {selector}")
                    print("  â†’ ç­‰å¾…CloudflareéªŒè¯å®Œæˆ...")
                    await asyncio.sleep(10)  # ç­‰å¾…éªŒè¯
                    break
            
            # æˆªå›¾
            screenshot_path = output_dir / f"{name.lower().replace(' ', '_')}_screenshot.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            # åˆ†ææ–‡ç« åˆ—è¡¨ - å°è¯•å¤šç§é€‰æ‹©å™¨
            print("\nğŸ” åˆ†ææ–‡ç« åˆ—è¡¨...")
            article_selectors = [
                "article",
                ".article",
                ".article-card",
                ".article-item",
                ".news-item",
                ".news-card",
                ".post",
                ".post-item",
                ".entry",
                ".entry-item",
                ".item",
                "[data-testid*='article']",
                "[data-testid*='news']",
                "[data-testid*='post']",
                ".card",
                ".story",
                ".story-card",
                "li[class*='article']",
                "div[class*='article']"
            ]
            
            found_articles = []
            working_selector = None
            
            for selector in article_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    if elements and len(elements) > 0:
                        # æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§ä¸”åŒ…å«é“¾æ¥
                        visible_count = 0
                        for elem in elements[:10]:  # æ£€æŸ¥å‰10ä¸ª
                            if await elem.is_visible():
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«é“¾æ¥
                                link = await elem.query_selector("a[href]")
                                if link:
                                    visible_count += 1
                        
                        if visible_count >= 3:  # è‡³å°‘3ä¸ªå¯è§çš„æ–‡ç« 
                            print(f"  âœ“ æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ï¼Œ{visible_count} ä¸ªå¯è§ (é€‰æ‹©å™¨: {selector})")
                            found_articles = elements
                            working_selector = selector
                            result['article_selector'] = selector
                            break
                except Exception as e:
                    continue
            
            if not found_articles:
                print("  âœ— æœªæ‰¾åˆ°æ–‡ç« åˆ—è¡¨ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                # å°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ–°é—»é“¾æ¥çš„å…ƒç´ 
                all_links = await page.query_selector_all("a[href*='/news'], a[href*='/article'], a[href*='/story']")
                if all_links:
                    print(f"  â†’ æ‰¾åˆ° {len(all_links)} ä¸ªå¯èƒ½çš„æ–°é—»é“¾æ¥")
                    # å°è¯•æ‰¾åˆ°è¿™äº›é“¾æ¥çš„çˆ¶å®¹å™¨
                    for link in all_links[:10]:
                        parent = await link.evaluate_handle("el => el.closest('article, .card, .item, div[class*=\"article\"], div[class*=\"news\"]')")
                        if parent:
                            found_articles.append(parent)
                    if found_articles:
                        result['article_selector'] = "a[href*='/news'], a[href*='/article'] -> parent"
                        working_selector = "custom"
            
            # åˆ†æå‰3ä¸ªæ–‡ç« å…ƒç´ 
            if found_articles:
                print(f"\nğŸ“ åˆ†ææ–‡ç« å…ƒç´ ï¼ˆå‰{min(3, len(found_articles))}ä¸ªï¼‰...")
                
                for idx, article in enumerate(found_articles[:3]):
                    print(f"\n  æ–‡ç«  #{idx + 1}:")
                    article_data = {}
                    
                    # æå–HTMLç»“æ„ï¼ˆç¬¬ä¸€ä¸ªï¼‰
                    if idx == 0:
                        html = await article.inner_html()
                        html_path = output_dir / f"{name.lower().replace(' ', '_')}_article_structure.html"
                        with open(html_path, 'w', encoding='utf-8') as f:
                            f.write(html)
                        print(f"  ğŸ“„ HTMLç»“æ„å·²ä¿å­˜: {html_path}")
                    
                    # æ ‡é¢˜
                    title_selectors = [
                        "h1", "h2", "h3", "h4",
                        ".title", ".headline", ".article-title",
                        "[data-testid*='title']",
                        "a[href] > *:first-child"
                    ]
                    for selector in title_selectors:
                        try:
                            title_elem = await article.query_selector(selector)
                            if title_elem:
                                title_text = await title_elem.inner_text()
                                if title_text and len(title_text.strip()) > 5:
                                    article_data['title'] = title_text.strip()
                                    article_data['title_selector'] = selector
                                    if not result['title_selector']:
                                        result['title_selector'] = selector
                                    print(f"    âœ“ æ ‡é¢˜: {title_text[:60]}... (é€‰æ‹©å™¨: {selector})")
                                    break
                        except:
                            continue
                    
                    # é“¾æ¥
                    link_selectors = [
                        "a[href]",
                        "a.article-link",
                        "a[href*='/news']",
                        "a[href*='/article']"
                    ]
                    for selector in link_selectors:
                        try:
                            link_elem = await article.query_selector(selector)
                            if link_elem:
                                href = await link_elem.get_attribute("href")
                                if href:
                                    # è½¬æ¢ä¸ºç»å¯¹URL
                                    if href.startswith('/'):
                                        from urllib.parse import urljoin
                                        href = urljoin(url, href)
                                    elif not href.startswith('http'):
                                        href = f"{url.rstrip('/')}/{href.lstrip('/')}"
                                    article_data['url'] = href
                                    article_data['link_selector'] = selector
                                    if not result['link_selector']:
                                        result['link_selector'] = selector
                                    print(f"    âœ“ é“¾æ¥: {href[:80]}... (é€‰æ‹©å™¨: {selector})")
                                    break
                        except:
                            continue
                    
                    # æ—¥æœŸ
                    date_selectors = [
                        "time[datetime]",
                        "time",
                        ".date",
                        ".publish-date",
                        ".published-date",
                        "[datetime]",
                        ".timestamp",
                        "[data-testid*='date']"
                    ]
                    for selector in date_selectors:
                        try:
                            date_elem = await article.query_selector(selector)
                            if date_elem:
                                date_text = await date_elem.inner_text()
                                datetime_attr = await date_elem.get_attribute("datetime")
                                date_value = datetime_attr or date_text
                                if date_value:
                                    article_data['publish_date'] = date_value.strip()
                                    article_data['date_selector'] = selector
                                    if not result['date_selector']:
                                        result['date_selector'] = selector
                                    print(f"    âœ“ æ—¥æœŸ: {date_value} (é€‰æ‹©å™¨: {selector})")
                                    break
                        except:
                            continue
                    
                    # æ‘˜è¦
                    summary_selectors = [
                        ".summary",
                        ".excerpt",
                        ".description",
                        ".article-summary",
                        "p",
                        ".snippet"
                    ]
                    for selector in summary_selectors:
                        try:
                            summary_elem = await article.query_selector(selector)
                            if summary_elem:
                                summary_text = await summary_elem.inner_text()
                                if summary_text and len(summary_text.strip()) > 20:
                                    article_data['summary'] = summary_text.strip()[:200]
                                    article_data['summary_selector'] = selector
                                    if not result['summary_selector']:
                                        result['summary_selector'] = selector
                                    print(f"    âœ“ æ‘˜è¦: {summary_text[:60]}... (é€‰æ‹©å™¨: {selector})")
                                    break
                        except:
                            continue
                    
                    if article_data:
                        result['extracted_data'].append(article_data)
                
                # éªŒè¯æå–ç»“æœ
                print(f"\nâœ… æå–éªŒè¯:")
                print(f"  æ–‡ç« æ•°é‡: {len(result['extracted_data'])}")
                for i, data in enumerate(result['extracted_data']):
                    has_title = 'title' in data
                    has_url = 'url' in data
                    has_date = 'publish_date' in data
                    has_summary = 'summary' in data
                    print(f"  æ–‡ç«  {i+1}: æ ‡é¢˜={has_title} é“¾æ¥={has_url} æ—¥æœŸ={has_date} æ‘˜è¦={has_summary}")
            
            # ä¿å­˜åˆ†æç»“æœ
            result_path = output_dir / f"{name.lower().replace(' ', '_')}_analysis.json"
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜: {result_path}")
            
            return result
            
        except Exception as e:
            print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            result['error'] = str(e)
            return result
        
        finally:
            print(f"\nâ¸ï¸  ç­‰å¾…5ç§’åå…³é—­æµè§ˆå™¨...")
            await asyncio.sleep(5)
            await browser.close()


async def main():
    """ä¸»å‡½æ•° - åˆ†æå•ä¸ªç½‘ç«™"""
    import sys
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python analyze_single_website.py <ç½‘ç«™åç§°> <URL> [zipcode]")
        print("\nç¤ºä¾‹:")
        print("  python analyze_single_website.py Newsbreak 'https://www.newsbreak.com/search?q=90210' 90210")
        print("  python analyze_single_website.py Realtor 'https://www.realtor.com/news/real-estate-news/'")
        sys.exit(1)
    
    name = sys.argv[1]
    url = sys.argv[2]
    zipcode = sys.argv[3] if len(sys.argv) > 3 else None
    
    result = await analyze_single_website(name, url, zipcode)
    
    print(f"\n{'='*70}")
    print("åˆ†æå®Œæˆï¼")
    print(f"{'='*70}\n")
    
    # è¾“å‡ºå…³é”®ä¿¡æ¯
    if result.get('article_selector'):
        print("âœ… æ‰¾åˆ°çš„é€‰æ‹©å™¨:")
        print(f"  æ–‡ç« åˆ—è¡¨: {result['article_selector']}")
        if result.get('title_selector'):
            print(f"  æ ‡é¢˜: {result['title_selector']}")
        if result.get('link_selector'):
            print(f"  é“¾æ¥: {result['link_selector']}")
        if result.get('date_selector'):
            print(f"  æ—¥æœŸ: {result['date_selector']}")
        if result.get('summary_selector'):
            print(f"  æ‘˜è¦: {result['summary_selector']}")
    else:
        print("âŒ æœªèƒ½æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡ç« é€‰æ‹©å™¨")


if __name__ == "__main__":
    asyncio.run(main())
