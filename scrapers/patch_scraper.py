"""
Patch.comé‡‡é›†å™¨
é‡‡é›†åŸºäºZipcodeçš„å±€éƒ¨æ–°é—»
"""
import re
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from scrapers.local_news_scraper import LocalNewsScraper
from scrapers.robust_scraper_mixin import RobustScraperMixin
from utils.logger import logger


class PatchScraper(LocalNewsScraper, RobustScraperMixin):
    """Patch.comæ–°é—»é‡‡é›†å™¨"""
    
    def __init__(self, debug_mode: bool = False):
        """
        åˆå§‹åŒ–Patché‡‡é›†å™¨
        
        Args:
            debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆheadless=Falseï¼Œè¯¦ç»†æ—¥å¿—ï¼Œæˆªå›¾ï¼‰
        """
        super().__init__("Patch")
        self.debug_mode = debug_mode
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ç›®å½•åˆ›å»ºæˆåŠŸ
        project_root = Path(__file__).parent.parent
        self.debug_screenshot_dir = project_root / "logs" / "patch_debug_screenshots"
        if self.debug_mode:
            self.debug_screenshot_dir.mkdir(parents=True, exist_ok=True)
            import sys
            print(f"ğŸ” [DEBUG] è°ƒè¯•æ¨¡å¼å·²å¯ç”¨", flush=True)
            print(f"ğŸ” [DEBUG] æˆªå›¾ç›®å½•: {self.debug_screenshot_dir.absolute()}", flush=True)
            sys.stdout.flush()
    
    async def _take_debug_screenshot(self, page, step_name: str):
        """åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æˆªå›¾"""
        if self.debug_mode and page:
            try:
                screenshot_path = self.debug_screenshot_dir / f"{step_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                await page.screenshot(path=str(screenshot_path), full_page=True)
                abs_path = screenshot_path.absolute()
                print(f"ğŸ” [DEBUG] æˆªå›¾å·²ä¿å­˜: {abs_path}")
                logger.info(f"ğŸ” [DEBUG] æˆªå›¾å·²ä¿å­˜: {abs_path}")
            except Exception as e:
                error_msg = f"æˆªå›¾å¤±è´¥: {str(e)}"
                print(f"âš ï¸ [DEBUG] {error_msg}")
                logger.debug(error_msg)
    
    async def _verify_browser_state(self, page) -> bool:
        """
        éªŒè¯æµè§ˆå™¨ã€contextå’Œpageçš„çŠ¶æ€
        
        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            
        Returns:
            Trueå¦‚æœæµè§ˆå™¨çŠ¶æ€æœ‰æ•ˆï¼ŒFalseå¦åˆ™
        """
        try:
            # æ£€æŸ¥æµè§ˆå™¨å¯¹è±¡
            if not self.browser:
                logger.warning(f"{self.source_name}: æµè§ˆå™¨å¯¹è±¡ä¸ºNone")
                return False
            
            # æ£€æŸ¥æµè§ˆå™¨è¿æ¥
            try:
                _ = self.browser.contexts
            except Exception as e:
                logger.warning(f"{self.source_name}: æµè§ˆå™¨è¿æ¥å·²æ–­å¼€: {str(e)}")
                return False
            
            # æ£€æŸ¥context
            if not self.context:
                logger.warning(f"{self.source_name}: Contextå¯¹è±¡ä¸ºNone")
                return False
            
            # æ£€æŸ¥page
            if not page:
                logger.warning(f"{self.source_name}: Pageå¯¹è±¡ä¸ºNone")
                return False
            
            # æ£€æŸ¥pageæ˜¯å¦å·²å…³é—­
            try:
                _ = page.url
            except Exception as e:
                logger.warning(f"{self.source_name}: Pageå·²å…³é—­: {str(e)}")
                return False
            
            return True
        except Exception as e:
            logger.warning(f"{self.source_name}: æµè§ˆå™¨çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
            return False
    
    async def _scrape_zipcode_news(self, zipcode: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        é‡‡é›†Patch.comçš„Zipcodeæ–°é—»
        
        Args:
            zipcode: é‚®æ”¿ç¼–ç 
            limit: é‡‡é›†æ•°é‡é™åˆ¶
            
        Returns:
            æ–‡ç« åˆ—è¡¨
        """
        articles = []
        page = None
        
        try:
            # è°ƒè¯•æ¨¡å¼ï¼šä½¿ç”¨headless=Falseä»¥ä¾¿è§‚å¯Ÿ
            import sys
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œæµè§ˆå™¨å°†ä»¥å¯è§æ¨¡å¼è¿è¡Œ", flush=True)
                print(f"ğŸ” [DEBUG] æˆªå›¾å°†ä¿å­˜åˆ°: {self.debug_screenshot_dir}", flush=True)
                sys.stdout.flush()
                logger.info(f"ğŸ” [DEBUG] è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œæµè§ˆå™¨å°†ä»¥å¯è§æ¨¡å¼è¿è¡Œ")
                logger.info(f"ğŸ” [DEBUG] æˆªå›¾å°†ä¿å­˜åˆ°: {self.debug_screenshot_dir}")
            
            print(f"ğŸ” [DEBUG] æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...", flush=True)
            sys.stdout.flush()
            # æ³¨æ„ï¼šå³ä½¿debug_mode=Trueï¼Œä¹Ÿä½¿ç”¨headless=Trueä»¥é¿å…macOSæƒé™é—®é¢˜
            # è°ƒè¯•åŠŸèƒ½ï¼ˆæ—¥å¿—ã€æˆªå›¾ï¼‰åœ¨headlessæ¨¡å¼ä¸‹ä»ç„¶å¯ç”¨
            # å¦‚æœéœ€è¦è§‚å¯Ÿæµè§ˆå™¨çª—å£ï¼Œå¯ä»¥æ‰‹åŠ¨ä¿®æ”¹è¿™é‡Œä¸º headless=False
            use_headless = True  # æ”¹ä¸ºFalseå¦‚æœéœ€è¦è§‚å¯Ÿæµè§ˆå™¨çª—å£
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] ä½¿ç”¨headless={use_headless}æ¨¡å¼ï¼ˆè°ƒè¯•åŠŸèƒ½ä»ç„¶å¯ç”¨ï¼‰", flush=True)
                sys.stdout.flush()
            await self._setup_browser(headless=use_headless)
            
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] æµè§ˆå™¨å·²å¯åŠ¨", flush=True)
                sys.stdout.flush()
                logger.info(f"ğŸ” [DEBUG] æµè§ˆå™¨å·²å¯åŠ¨")
                
                # ç«‹å³æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
                if not self.browser:
                    print(f"âŒ [DEBUG] æµè§ˆå™¨å¯¹è±¡ä¸ºNoneï¼", flush=True)
                    sys.stdout.flush()
                    raise Exception("æµè§ˆå™¨å¯åŠ¨åå¯¹è±¡ä¸ºNone")
                
                # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦ä»ç„¶è¿æ¥
                try:
                    contexts = self.browser.contexts
                    print(f"ğŸ” [DEBUG] æµè§ˆå™¨è¿æ¥æ­£å¸¸ï¼Œå½“å‰æœ‰ {len(contexts)} ä¸ªä¸Šä¸‹æ–‡", flush=True)
                    sys.stdout.flush()
                except Exception as e:
                    print(f"âŒ [DEBUG] æµè§ˆå™¨è¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}", flush=True)
                    sys.stdout.flush()
                    raise Exception(f"æµè§ˆå™¨è¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}")
                
                # åœ¨headless=Falseæ¨¡å¼ä¸‹ï¼Œç»™æµè§ˆå™¨æ›´å¤šæ—¶é—´ç¨³å®šï¼ˆä½†åˆ†æ®µæ£€æŸ¥ï¼‰
                print(f"ğŸ” [DEBUG] ç­‰å¾…æµè§ˆå™¨ç¨³å®š...", flush=True)
                sys.stdout.flush()
                for i in range(5):  # 5ç§’ï¼Œæ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                    await asyncio.sleep(1)
                    if not self.browser:
                        print(f"âŒ [DEBUG] æµè§ˆå™¨åœ¨ç¬¬ {i+1} ç§’æ—¶æ–­å¼€ï¼", flush=True)
                        sys.stdout.flush()
                        raise Exception(f"æµè§ˆå™¨åœ¨ç­‰å¾…æœŸé—´æ–­å¼€ï¼ˆç¬¬{i+1}ç§’ï¼‰")
                    try:
                        _ = self.browser.contexts
                    except Exception as e:
                        print(f"âŒ [DEBUG] æµè§ˆå™¨åœ¨ç¬¬ {i+1} ç§’æ—¶è¿æ¥å¤±è´¥: {str(e)}", flush=True)
                        sys.stdout.flush()
                        raise Exception(f"æµè§ˆå™¨è¿æ¥å¤±è´¥ï¼ˆç¬¬{i+1}ç§’ï¼‰: {str(e)}")
                
                print(f"âœ… [DEBUG] æµè§ˆå™¨ç¨³å®šæ£€æŸ¥å®Œæˆ", flush=True)
                sys.stdout.flush()
            
            # éªŒè¯æµè§ˆå™¨çŠ¶æ€
            if not self.browser:
                if self.debug_mode:
                    print(f"âŒ [DEBUG] æµè§ˆå™¨å¯åŠ¨å¤±è´¥æˆ–å·²æ–­å¼€", flush=True)
                    sys.stdout.flush()
                raise Exception("æµè§ˆå™¨å¯åŠ¨å¤±è´¥æˆ–å·²æ–­å¼€")
            
            try:
                # éªŒè¯æµè§ˆå™¨æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                _ = self.browser.contexts
                if self.debug_mode:
                    print(f"ğŸ” [DEBUG] æµè§ˆå™¨çŠ¶æ€éªŒè¯æˆåŠŸ", flush=True)
                    sys.stdout.flush()
            except Exception as e:
                if self.debug_mode:
                    print(f"âŒ [DEBUG] æµè§ˆå™¨çŠ¶æ€éªŒè¯å¤±è´¥: {str(e)}", flush=True)
                    sys.stdout.flush()
                raise Exception(f"æµè§ˆå™¨åœ¨åˆ›å»ºé¡µé¢å‰å·²æ–­å¼€: {str(e)}")
            
            # åˆ›å»ºé¡µé¢ï¼Œå¸¦é‡è¯•æœºåˆ¶
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] å°è¯•åˆ›å»ºé¡µé¢ï¼ˆ{attempt + 1}/{max_retries}ï¼‰...", flush=True)
                        sys.stdout.flush()
                    
                    # åœ¨åˆ›å»ºé¡µé¢å‰ï¼Œå†æ¬¡æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
                    if not self.browser:
                        if self.debug_mode:
                            print(f"âŒ [DEBUG] æµè§ˆå™¨å¯¹è±¡ä¸ºNoneï¼Œæ— æ³•åˆ›å»ºé¡µé¢", flush=True)
                            sys.stdout.flush()
                        raise Exception("æµè§ˆå™¨å¯¹è±¡ä¸ºNone")
                    
                    try:
                        _ = self.browser.contexts
                        if self.debug_mode:
                            print(f"ğŸ” [DEBUG] æµè§ˆå™¨è¿æ¥æ­£å¸¸ï¼Œå‡†å¤‡åˆ›å»ºcontext...", flush=True)
                            sys.stdout.flush()
                    except Exception as e:
                        if self.debug_mode:
                            print(f"âŒ [DEBUG] æµè§ˆå™¨è¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}", flush=True)
                            sys.stdout.flush()
                        raise Exception(f"æµè§ˆå™¨è¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}")
                    
                    # åœ¨headless=Falseæ¨¡å¼ä¸‹ï¼Œåˆ›å»ºcontextå‰é¢å¤–ç­‰å¾…
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] ç­‰å¾…1ç§’ååˆ›å»ºcontext...", flush=True)
                        sys.stdout.flush()
                        await asyncio.sleep(1)
                    
                    page = await self._create_page()
                    if self.debug_mode:
                        print(f"âœ… [DEBUG] é¡µé¢å·²åˆ›å»ºæˆåŠŸï¼", flush=True)
                        sys.stdout.flush()
                    logger.info(f"ğŸ” [DEBUG] é¡µé¢å·²åˆ›å»º")
                    break
                except Exception as e:
                    error_msg = str(e)
                    if self.debug_mode:
                        print(f"âš ï¸ [DEBUG] åˆ›å»ºé¡µé¢å¤±è´¥: {error_msg[:150]}", flush=True)
                        sys.stdout.flush()
                    
                    if attempt < max_retries - 1:
                        if self.debug_mode:
                            print(f"ğŸ” [DEBUG] ç­‰å¾…3ç§’åé‡è¯•... ({attempt + 1}/{max_retries})", flush=True)
                            sys.stdout.flush()
                        await asyncio.sleep(3)
                        # é‡æ–°éªŒè¯æµè§ˆå™¨
                        if not self.browser:
                            if self.debug_mode:
                                print(f"âŒ [DEBUG] æµè§ˆå™¨å·²æ–­å¼€ï¼Œæ— æ³•é‡è¯•", flush=True)
                                sys.stdout.flush()
                            raise Exception("æµè§ˆå™¨å·²æ–­å¼€ï¼Œæ— æ³•é‡è¯•")
                    else:
                        if self.debug_mode:
                            print(f"âŒ [DEBUG] åˆ›å»ºé¡µé¢å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡", flush=True)
                            sys.stdout.flush()
                        raise
            
            # è®¿é—®Patchä¸»é¡µ
            # å·¥ä½œæµç¨‹ï¼šè®¿é—®ä¸»é¡µ â†’ è¾“å…¥zipcode â†’ è‡ªåŠ¨å®Œæˆå»ºè®® â†’ ç‚¹å‡»å»ºè®® â†’ è·³è½¬åˆ°zipcodeå¯¹åº”é¡µé¢ â†’ æå–æ–‡ç« 
            home_url = "https://patch.com/"
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] æ­¥éª¤1: è®¿é—®ä¸»é¡µ: {home_url}")
            logger.info(f"ğŸ” [DEBUG] æ­¥éª¤1: è®¿é—®ä¸»é¡µ: {home_url}")
            
            # ä½¿ç”¨æ›´å®½æ¾çš„ç­‰å¾…ç­–ç•¥ï¼Œé¿å…è¶…æ—¶ï¼ˆä¸Redfin/Newsbreakä¿æŒä¸€è‡´ï¼‰
            try:
                logger.debug(f"{self.source_name}: ç­‰å¾…é¡µé¢åŠ è½½ (domcontentloaded)...")
                await page.goto(home_url, wait_until="domcontentloaded", timeout=30000)
                logger.debug(f"{self.source_name}: é¡µé¢DOMå·²åŠ è½½")
            except Exception as goto_error:
                # å¦‚æœdomcontentloadedå¤±è´¥ï¼Œå°è¯•æ›´å®½æ¾çš„ç­–ç•¥
                logger.warning(f"{self.source_name}: domcontentloadedå¤±è´¥ï¼Œå°è¯•commit: {str(goto_error)[:100]}")
                try:
                    await page.goto(home_url, wait_until="commit", timeout=30000)
                    logger.debug(f"{self.source_name}: é¡µé¢å¯¼èˆªå·²æäº¤")
                except Exception as e2:
                    logger.error(f"{self.source_name}: é¡µé¢å¯¼èˆªå®Œå…¨å¤±è´¥: {str(e2)[:100]}", exc_info=True)
                    raise
            
            await self._random_delay()
            
            # è°ƒè¯•ï¼šè®°å½•åˆå§‹URLå’Œé¡µé¢æ ‡é¢˜
            initial_url = page.url
            page_title = await page.title()
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] åˆå§‹URL: {initial_url}")
                print(f"ğŸ” [DEBUG] é¡µé¢æ ‡é¢˜: {page_title}")
            logger.info(f"ğŸ” [DEBUG] åˆå§‹URL: {initial_url}")
            logger.info(f"ğŸ” [DEBUG] é¡µé¢æ ‡é¢˜: {page_title}")
            await self._take_debug_screenshot(page, "01_initial_page")
            
            # å¤„ç†å¯èƒ½çš„å¼¹çª—
            try:
                close_buttons = await page.query_selector_all(
                    "button[aria-label*='close'], button[aria-label*='Close'], .close-button"
                )
                for btn in close_buttons[:1]:
                    try:
                        await btn.click(timeout=2000)
                        await self._random_delay(0.5, 1.0)
                    except Exception as e:
                        logger.debug(f"å…³é—­å¼¹çª—å¤±è´¥: {str(e)}")
            except Exception as e:
                logger.debug(f"æŸ¥æ‰¾å¼¹çª—æŒ‰é’®å¤±è´¥: {str(e)}")
            
            # æ­¥éª¤2: æŸ¥æ‰¾å¹¶è¾“å…¥zipcodeåˆ°è¾“å…¥æ¡†
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] æ­¥éª¤2: æŸ¥æ‰¾zipcodeè¾“å…¥æ¡† #find-your-patch")
            logger.info(f"ğŸ” [DEBUG] æ­¥éª¤2: æŸ¥æ‰¾zipcodeè¾“å…¥æ¡† #find-your-patch")
            try:
                # æ»šåŠ¨åˆ°é¡µé¢é¡¶éƒ¨ï¼Œç¡®ä¿è¾“å…¥æ¡†å¯è§
                await page.evaluate("window.scrollTo(0, 0)")
                await asyncio.sleep(0.5)  # ç­‰å¾…æ»šåŠ¨å®Œæˆ
                
                # å°è¯•å¤šä¸ªé€‰æ‹©å™¨ï¼Œç­‰å¾…è¾“å…¥æ¡†å‡ºç°
                zipcode_input = None
                zipcode_selectors = [
                    "#find-your-patch",
                    "input#find-your-patch",
                    "input[placeholder*='ZIP code' i]",
                    "input[placeholder*='town' i]",
                    ".find-your-patch",
                    "input.find-your-patch"
                ]
                
                for selector in zipcode_selectors:
                    try:
                        zipcode_input = await page.wait_for_selector(selector, timeout=5000, state="visible")
                        if zipcode_input:
                            if self.debug_mode:
                                print(f"ğŸ” [DEBUG] æ‰¾åˆ°zipcodeè¾“å…¥æ¡†: {selector}")
                            logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ°zipcodeè¾“å…¥æ¡†: {selector}")
                            break
                    except Exception as e:
                        logger.debug(f"ç­‰å¾…é€‰æ‹©å™¨ {selector} è¶…æ—¶: {str(e)}")
                        continue
                
                if zipcode_input:
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] æ‰¾åˆ°zipcodeè¾“å…¥æ¡†ï¼Œè¾“å…¥zipcode: {zipcode}")
                    logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ°zipcodeè¾“å…¥æ¡†ï¼Œè¾“å…¥zipcode: {zipcode}")
                    
                    # è¾“å…¥zipcodeå‰æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
                    if not await self._verify_browser_state(page):
                        logger.warning(f"{self.source_name}: è¾“å…¥zipcodeå‰æµè§ˆå™¨çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆ›å»º")
                        await self.cleanup()
                        await self._setup_browser(headless=True)
                        page = await self._create_page()
                        # é‡æ–°è®¿é—®ä¸»é¡µå¹¶æŸ¥æ‰¾è¾“å…¥æ¡†
                        await page.goto("https://patch.com/", wait_until="domcontentloaded", timeout=30000)
                        await asyncio.sleep(1)
                        zipcode_input = await page.wait_for_selector("input[placeholder*='ZIP code' i]", timeout=5000, state="visible")
                        if not zipcode_input:
                            raise Exception("é‡æ–°åˆ›å»ºæµè§ˆå™¨åä»æ— æ³•æ‰¾åˆ°è¾“å…¥æ¡†")
                    
                    await zipcode_input.fill(zipcode)
                    # ç­‰å¾…3ç§’ï¼Œç¡®ä¿è‡ªåŠ¨å®Œæˆå»ºè®®åŠ è½½å®Œæˆï¼ˆåŸºäºå®é™…æµ‹è¯•ï¼‰
                    await asyncio.sleep(3)
                    await self._take_debug_screenshot(page, "02_after_input")
                    
                    # æ­¥éª¤3: ç­‰å¾…å¹¶æ£€æµ‹è‡ªåŠ¨å®Œæˆå»ºè®®
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] æ­¥éª¤3: ç­‰å¾…è‡ªåŠ¨å®Œæˆå»ºè®®å‡ºç°...")
                    logger.info(f"ğŸ” [DEBUG] æ­¥éª¤3: ç­‰å¾…è‡ªåŠ¨å®Œæˆå»ºè®®å‡ºç°...")
                    # ä½¿ç”¨å®é™…å‘ç°çš„é€‰æ‹©å™¨
                    autocomplete_selectors = [
                        ".autocomplete__dropdown",  # å®é™…å‘ç°çš„å®¹å™¨é€‰æ‹©å™¨
                        ".autocomplete__list",      # åˆ—è¡¨é€‰æ‹©å™¨
                        "[class*='autocomplete']",  # fallback
                        "[class*='dropdown']"       # fallback
                    ]
                    
                    autocomplete_found = False
                    autocomplete_element = None
                    for selector in autocomplete_selectors:
                        try:
                            autocomplete_element = await page.wait_for_selector(selector, timeout=5000, state="visible")
                            if autocomplete_element:
                                if self.debug_mode:
                                    print(f"ğŸ” [DEBUG] æ‰¾åˆ°è‡ªåŠ¨å®Œæˆå®¹å™¨: {selector}")
                                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ°è‡ªåŠ¨å®Œæˆå®¹å™¨: {selector}")
                                autocomplete_found = True
                                await self._take_debug_screenshot(page, "03_autocomplete_appeared")
                                break
                        except Exception as e:
                            logger.debug(f"ç­‰å¾…é€‰æ‹©å™¨ {selector} è¶…æ—¶: {str(e)}")
                            continue
                    
                    if not autocomplete_found:
                        logger.warning(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°è‡ªåŠ¨å®Œæˆå»ºè®®ï¼Œç­‰å¾…é¢å¤–2ç§’åç»§ç»­...")
                        await asyncio.sleep(2)
                        await self._take_debug_screenshot(page, "03_no_autocomplete")
                    
                    # æ­¥éª¤4: æ£€æµ‹è‡ªåŠ¨å®Œæˆå»ºè®®é¡¹
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] æ­¥éª¤4: æ£€æµ‹è‡ªåŠ¨å®Œæˆå»ºè®®é¡¹...")
                    logger.info(f"ğŸ” [DEBUG] æ­¥éª¤4: æ£€æµ‹è‡ªåŠ¨å®Œæˆå»ºè®®é¡¹...")
                    # ä½¿ç”¨å®é™…å‘ç°çš„é€‰æ‹©å™¨
                    suggestion_selectors = [
                        ".autocomplete__list-item a.autocomplete__btn",  # å®é™…å‘ç°çš„é“¾æ¥é€‰æ‹©å™¨
                        ".autocomplete__list-item a",                   # åˆ—è¡¨é¡¹ä¸­çš„é“¾æ¥
                        ".autocomplete__btn",                           # æŒ‰é’®é€‰æ‹©å™¨
                        ".autocomplete__list-item"                      # åˆ—è¡¨é¡¹é€‰æ‹©å™¨
                    ]
                    
                    suggestions = []
                    for selector in suggestion_selectors:
                        try:
                            suggestions = await page.query_selector_all(selector)
                            if suggestions:
                                if self.debug_mode:
                                    print(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(suggestions)} ä¸ªå»ºè®®é¡¹ (é€‰æ‹©å™¨: {selector})")
                                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(suggestions)} ä¸ªå»ºè®®é¡¹ (é€‰æ‹©å™¨: {selector})")
                                # è®°å½•å»ºè®®é¡¹æ–‡æœ¬
                                for i, suggestion in enumerate(suggestions[:5]):  # åªè®°å½•å‰5ä¸ª
                                    try:
                                        text = await suggestion.inner_text()
                                        if self.debug_mode:
                                            print(f"ğŸ” [DEBUG]   å»ºè®®é¡¹ {i+1}: {text[:100]}")
                                        logger.info(f"ğŸ” [DEBUG]   å»ºè®®é¡¹ {i+1}: {text[:100]}")
                                    except Exception:
                                        pass
                                break
                        except Exception as e:
                            logger.debug(f"æŸ¥è¯¢å»ºè®®é¡¹é€‰æ‹©å™¨ {selector} å¤±è´¥: {str(e)}")
                            continue
                    
                    # æ­¥éª¤5: è·å–ç¬¬ä¸€ä¸ªå»ºè®®é¡¹çš„URLå¹¶å¯¼èˆªï¼ˆé¿å…ç‚¹å‡»å¯¼è‡´çš„æµè§ˆå™¨å´©æºƒï¼‰
                    if suggestions:
                        if self.debug_mode:
                            print(f"ğŸ” [DEBUG] æ­¥éª¤5: è·å–ç¬¬ä¸€ä¸ªå»ºè®®é¡¹çš„URLå¹¶å¯¼èˆª...")
                        logger.info(f"ğŸ” [DEBUG] æ­¥éª¤5: è·å–ç¬¬ä¸€ä¸ªå»ºè®®é¡¹çš„URLå¹¶å¯¼èˆª...")
                        try:
                            # è·å–ç¬¬ä¸€ä¸ªå»ºè®®é¡¹çš„URL
                            first_suggestion = suggestions[0]
                            suggestion_url = await first_suggestion.get_attribute("href")
                            suggestion_text = await first_suggestion.inner_text()
                            
                            if not suggestion_url:
                                # å¦‚æœæ²¡æœ‰hrefï¼Œå°è¯•ä»çˆ¶å…ƒç´ è·å–
                                parent = await first_suggestion.query_selector("..")
                                if parent:
                                    suggestion_url = await parent.get_attribute("href")
                            
                            if suggestion_url:
                                # æ„å»ºå®Œæ•´URL
                                if suggestion_url.startswith('/'):
                                    target_url = f"https://patch.com{suggestion_url}"
                                elif suggestion_url.startswith('http'):
                                    target_url = suggestion_url
                                else:
                                    target_url = f"https://patch.com/{suggestion_url}"
                                
                                if self.debug_mode:
                                    print(f"ğŸ” [DEBUG] å»ºè®®é¡¹æ–‡æœ¬: {suggestion_text}")
                                    print(f"ğŸ” [DEBUG] å»ºè®®é¡¹URL: {suggestion_url}")
                                    print(f"ğŸ” [DEBUG] ç›®æ ‡URL: {target_url}")
                                logger.info(f"ğŸ” [DEBUG] å»ºè®®é¡¹æ–‡æœ¬: {suggestion_text}")
                                logger.info(f"ğŸ” [DEBUG] å»ºè®®é¡¹URL: {suggestion_url}")
                                logger.info(f"ğŸ” [DEBUG] ç›®æ ‡URL: {target_url}")
                                
                                # å¯¼èˆªåˆ°ç›®æ ‡URLï¼Œå¸¦é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤šé‡è¯•2æ¬¡ï¼‰
                                max_navigation_retries = 2
                                navigation_success = False
                                
                                for nav_attempt in range(max_navigation_retries + 1):  # åˆå§‹å°è¯• + 2æ¬¡é‡è¯• = æ€»å…±3æ¬¡
                                    try:
                                        # å¯¼èˆªå‰æ£€æŸ¥æµè§ˆå™¨çŠ¶æ€
                                        if not await self._verify_browser_state(page):
                                            logger.warning(f"{self.source_name}: å¯¼èˆªå‰æµè§ˆå™¨çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼ˆå°è¯• {nav_attempt + 1}/{max_navigation_retries + 1}ï¼‰")
                                            
                                            # å¦‚æœæµè§ˆå™¨æ— æ•ˆä¸”ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œå°è¯•é‡æ–°åˆ›å»º
                                            if nav_attempt < max_navigation_retries:
                                                logger.info(f"{self.source_name}: å°è¯•é‡æ–°åˆ›å»ºæµè§ˆå™¨å’Œé¡µé¢...")
                                                try:
                                                    # é‡æ–°åˆ›å»ºæµè§ˆå™¨å’Œé¡µé¢
                                                    await self.cleanup()
                                                    await self._setup_browser(headless=True)
                                                    page = await self._create_page()
                                                    
                                                    # é‡æ–°è®¿é—®ä¸»é¡µå¹¶è¾“å…¥zipcodeï¼ˆç®€åŒ–æµç¨‹ï¼Œç›´æ¥å¯¼èˆªåˆ°ç›®æ ‡URLï¼‰
                                                    logger.info(f"{self.source_name}: æµè§ˆå™¨å·²é‡æ–°åˆ›å»ºï¼Œç›´æ¥å¯¼èˆªåˆ°ç›®æ ‡URL")
                                                except Exception as recreate_error:
                                                    logger.error(f"{self.source_name}: é‡æ–°åˆ›å»ºæµè§ˆå™¨å¤±è´¥: {str(recreate_error)}")
                                                    if nav_attempt == max_navigation_retries:
                                                        raise
                                                    continue
                                            else:
                                                raise Exception("æµè§ˆå™¨çŠ¶æ€æ— æ•ˆä¸”å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                                        
                                        # æ‰§è¡Œå¯¼èˆª
                                        if nav_attempt == 0:
                                            # ç¬¬ä¸€æ¬¡å°è¯•ï¼šä½¿ç”¨domcontentloaded
                                            await page.goto(target_url, wait_until="domcontentloaded", timeout=30000)
                                        else:
                                            # é‡è¯•ï¼šä½¿ç”¨æ›´å®½æ¾çš„commitç­–ç•¥
                                            logger.info(f"{self.source_name}: å¯¼èˆªé‡è¯• {nav_attempt}/{max_navigation_retries}ï¼Œä½¿ç”¨commitç­–ç•¥")
                                            await page.goto(target_url, wait_until="commit", timeout=30000)
                                        
                                        if self.debug_mode:
                                            print(f"ğŸ” [DEBUG] å·²å¯¼èˆªåˆ°ç›®æ ‡URLï¼ˆå°è¯• {nav_attempt + 1}ï¼‰")
                                        logger.info(f"ğŸ” [DEBUG] å·²å¯¼èˆªåˆ°ç›®æ ‡URLï¼ˆå°è¯• {nav_attempt + 1}ï¼‰")
                                        await self._take_debug_screenshot(page, f"04_navigated_to_target_attempt_{nav_attempt + 1}")
                                        
                                        # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
                                        await asyncio.sleep(2)  # ç­‰å¾…å†…å®¹åŠ è½½
                                        await page.wait_for_load_state("domcontentloaded", timeout=10000)
                                        await asyncio.sleep(1)  # é¢å¤–ç­‰å¾…
                                        
                                        if self.debug_mode:
                                            print(f"ğŸ” [DEBUG] ç›®æ ‡é¡µé¢å·²åŠ è½½å®Œæˆ")
                                        logger.info(f"ğŸ” [DEBUG] ç›®æ ‡é¡µé¢å·²åŠ è½½å®Œæˆ")
                                        await self._take_debug_screenshot(page, "05_target_page_loaded")
                                        
                                        navigation_success = True
                                        break
                                        
                                    except Exception as goto_error:
                                        error_msg = str(goto_error)
                                        is_browser_closed = "closed" in error_msg.lower() or "disconnected" in error_msg.lower()
                                        
                                        if nav_attempt < max_navigation_retries:
                                            # è®¡ç®—é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼š1ç§’ã€2ç§’ï¼‰
                                            retry_delay = 2 ** nav_attempt
                                            logger.warning(
                                                f"{self.source_name}: å¯¼èˆªå¤±è´¥ï¼ˆå°è¯• {nav_attempt + 1}/{max_navigation_retries + 1}ï¼‰ï¼Œ"
                                                f"{retry_delay}ç§’åé‡è¯•ã€‚é”™è¯¯: {error_msg[:100]}"
                                            )
                                            
                                            if is_browser_closed:
                                                logger.warning(f"{self.source_name}: æ£€æµ‹åˆ°æµè§ˆå™¨å…³é—­é”™è¯¯ï¼Œå°†åœ¨é‡è¯•å‰é‡æ–°åˆ›å»ºæµè§ˆå™¨")
                                            
                                            await asyncio.sleep(retry_delay)
                                        else:
                                            # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥
                                            logger.error(
                                                f"{self.source_name}: é¡µé¢å¯¼èˆªå®Œå…¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_navigation_retries} æ¬¡ï¼‰ã€‚"
                                                f"ç›®æ ‡URL: {target_url}ï¼Œé”™è¯¯ç±»å‹: {'æµè§ˆå™¨å…³é—­' if is_browser_closed else 'å¯¼èˆªé”™è¯¯'}ï¼Œ"
                                                f"é”™è¯¯ä¿¡æ¯: {error_msg[:200]}",
                                                exc_info=True
                                            )
                                            raise
                                
                                if not navigation_success:
                                    raise Exception(f"å¯¼èˆªå¤±è´¥ï¼šç»è¿‡ {max_navigation_retries + 1} æ¬¡å°è¯•åä»æ— æ³•å¯¼èˆªåˆ° {target_url}")
                            else:
                                logger.warning(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°å»ºè®®é¡¹çš„URLï¼Œå°è¯•ç‚¹å‡»æ–¹å¼...")
                                # å›é€€åˆ°ç‚¹å‡»æ–¹å¼ï¼ˆä½†ä½¿ç”¨æ›´ç¨³å®šçš„æ–¹æ³•ï¼‰
                                try:
                                    # ä½¿ç”¨page.clickè€Œä¸æ˜¯element.clickï¼Œæ›´ç¨³å®š
                                    selector = ".autocomplete__list-item a.autocomplete__btn"
                                    await page.click(selector, timeout=5000)
                                    await asyncio.sleep(2)
                                    await page.wait_for_load_state("domcontentloaded", timeout=10000)
                                    await asyncio.sleep(1)
                                except Exception as click_error:
                                    logger.error(f"ğŸ” [DEBUG] ç‚¹å‡»å»ºè®®é¡¹ä¹Ÿå¤±è´¥: {str(click_error)}", exc_info=True)
                                    
                        except Exception as e:
                            logger.error(f"ğŸ” [DEBUG] å¤„ç†å»ºè®®é¡¹å¤±è´¥: {str(e)}", exc_info=True)
                    else:
                        logger.warning(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°å»ºè®®é¡¹ï¼Œå°è¯•ç‚¹å‡»æœç´¢æŒ‰é’®...")
                        # å›é€€åˆ°æœç´¢æŒ‰é’®
                        search_button = await page.query_selector("button[type='submit'], input[type='submit']")
                        if not search_button:
                            buttons = await page.query_selector_all("button")
                            for btn in buttons:
                                try:
                                    text = await btn.inner_text()
                                    if text and ('search' in text.lower() or 'find' in text.lower()):
                                        search_button = btn
                                        break
                                except Exception:
                                    continue
                        
                        if search_button:
                            logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ°æœç´¢æŒ‰é’®ï¼Œç‚¹å‡»...")
                            await search_button.click()
                            await self._random_delay(2, 4)
                            await self._take_debug_screenshot(page, "04_after_search_button")
                else:
                    logger.warning(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°zipcodeè¾“å…¥æ¡†")
            except Exception as e:
                logger.error(f"ğŸ” [DEBUG] å¤„ç†zipcodeè¾“å…¥æ¡†å¤±è´¥: {str(e)}", exc_info=True)
            
            # æ­¥éª¤6: åœ¨è·³è½¬åçš„é¡µé¢æŸ¥æ‰¾æ–‡ç« åˆ—è¡¨
            current_url = page.url
            current_title = await page.title()
            if self.debug_mode:
                print(f"ğŸ” [DEBUG] æ­¥éª¤6: åœ¨å½“å‰é¡µé¢æŸ¥æ‰¾æ–‡ç« åˆ—è¡¨")
                print(f"ğŸ” [DEBUG] å½“å‰URL: {current_url}")
                print(f"ğŸ” [DEBUG] å½“å‰é¡µé¢æ ‡é¢˜: {current_title}")
            logger.info(f"ğŸ” [DEBUG] æ­¥éª¤6: åœ¨å½“å‰é¡µé¢æŸ¥æ‰¾æ–‡ç« åˆ—è¡¨")
            logger.info(f"ğŸ” [DEBUG] å½“å‰URL: {current_url}")
            logger.info(f"ğŸ” [DEBUG] å½“å‰é¡µé¢æ ‡é¢˜: {current_title}")
            
            # ç­‰å¾…æ–‡ç« åˆ—è¡¨åŠ è½½ - ä½¿ç”¨å¤šç§å¤‡é€‰é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨å®é™…å‘ç°çš„é€‰æ‹©å™¨ï¼‰
            article_selectors = [
                "article.styles_ArticleCard__ZF3Wi",  # å®é™…å‘ç°çš„æ–‡ç« é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                "article.styles_Card__h4UC9",         # å®é™…å‘ç°çš„æ–‡ç« é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                ".patch-article-card",
                ".article-card",
                "article",
                "[data-testid='article']",
                ".card",
                "div[class*='article']",
                "div[class*='patch']",
                "div[class*='story']",
                "div[class*='post']",
                "main article",
                ".content article",
                ".article-list article",
                ".news-list article"
            ]
            
            # å°è¯•ç­‰å¾…ä»»ä¸€é€‰æ‹©å™¨
            found_selector = None
            for selector in article_selectors:
                try:
                    await page.wait_for_selector(selector, timeout=5000)
                    found_selector = selector
                    if self.debug_mode:
                        print(f"ğŸ” [DEBUG] æ‰¾åˆ°æ–‡ç« åˆ—è¡¨é€‰æ‹©å™¨: {selector}")
                    logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ°æ–‡ç« åˆ—è¡¨é€‰æ‹©å™¨: {selector}")
                    break
                except Exception as e:
                    logger.debug(f"ç­‰å¾…é€‰æ‹©å™¨ {selector} è¶…æ—¶: {str(e)}")
                    continue
            
            # ä½¿ç”¨robustæ–¹æ³•æŸ¥æ‰¾å…ƒç´ 
            article_elements = await self.find_elements_with_fallback(page, article_selectors)
            
            if not article_elements or len(article_elements) == 0:
                if self.debug_mode:
                    print(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°æ–‡ç« åˆ—è¡¨")
                    print(f"ğŸ” [DEBUG] å½“å‰URL: {current_url}")
                    print(f"ğŸ” [DEBUG] å½“å‰é¡µé¢æ ‡é¢˜: {current_title}")
                logger.warning(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°æ–‡ç« åˆ—è¡¨")
                logger.warning(f"ğŸ” [DEBUG] å½“å‰URL: {current_url}")
                logger.warning(f"ğŸ” [DEBUG] å½“å‰é¡µé¢æ ‡é¢˜: {current_title}")
                
                # è°ƒè¯•ï¼šå°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡ç« å®¹å™¨
                if self.debug_mode:
                    print(f"ğŸ” [DEBUG] å°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡ç« å®¹å™¨...")
                logger.info(f"ğŸ” [DEBUG] å°è¯•æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–‡ç« å®¹å™¨...")
                all_articles = await page.query_selector_all("article")
                all_cards = await page.query_selector_all(".card, [class*='card']")
                all_links = await page.query_selector_all("a[href*='/news'], a[href*='/article'], a[href*='/story']")
                
                if self.debug_mode:
                    print(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_articles)} ä¸ª <article> å…ƒç´ ")
                    print(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_cards)} ä¸ª .card å…ƒç´ ")
                    print(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_links)} ä¸ªæ–°é—»é“¾æ¥")
                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_articles)} ä¸ª <article> å…ƒç´ ")
                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_cards)} ä¸ª .card å…ƒç´ ")
                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(all_links)} ä¸ªæ–°é—»é“¾æ¥")
                
                await self._take_debug_screenshot(page, "06_no_articles_found")
            else:
                if self.debug_mode:
                    print(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(article_elements)} ä¸ªæ–‡ç« å…ƒç´  (ä½¿ç”¨é€‰æ‹©å™¨: {found_selector})")
                logger.info(f"ğŸ” [DEBUG] æ‰¾åˆ° {len(article_elements)} ä¸ªæ–‡ç« å…ƒç´  (ä½¿ç”¨é€‰æ‹©å™¨: {found_selector})")
                await self._take_debug_screenshot(page, "06_articles_found")
            
            for i, element in enumerate(article_elements[:limit]):
                try:
                    article = await self._extract_article_data(element, zipcode)
                    if article:
                        if self.debug_mode:
                            print(f"ğŸ” [DEBUG] æå–æ–‡ç«  {i+1}:")
                            print(f"  - æ ‡é¢˜: {article.get('title', '')[:80]}")
                            print(f"  - URL: {article.get('url', '')[:80]}")
                            print(f"  - æ—¥æœŸ: {article.get('publish_date', '')}")
                            print(f"  - æ‘˜è¦: {article.get('content_summary', '')[:80]}")
                        logger.debug(f"æå–æ–‡ç«  {i+1}: æ ‡é¢˜={article.get('title', '')[:50]}, URL={article.get('url', '')[:50]}")
                        articles.append(article)
                        await self._random_delay(0.3, 0.8)
                    else:
                        if self.debug_mode:
                            print(f"âš ï¸ [DEBUG] æ–‡ç«  {i+1} æå–å¤±è´¥ï¼ˆè¿”å›Noneï¼‰")
                        logger.warning(f"æ–‡ç«  {i+1} æå–å¤±è´¥ï¼ˆè¿”å›Noneï¼‰")
                except Exception as e:
                    logger.warning(f"æå–ç¬¬ {i+1} ç¯‡æ–‡ç« å¤±è´¥: {str(e)}", exc_info=True)
                    continue
            
        except Exception as e:
            if self.debug_mode:
                print(f"âŒ [DEBUG] Patché‡‡é›†è¿‡ç¨‹å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
            logger.error(f"Patché‡‡é›†è¿‡ç¨‹å‡ºé”™: {str(e)}", exc_info=True)
        finally:
            # ç¡®ä¿é¡µé¢å’Œæµè§ˆå™¨èµ„æºéƒ½è¢«æ¸…ç†
            # æ³¨æ„ï¼šä¸éœ€è¦å•ç‹¬å…³é—­pageï¼Œcleanup()ä¼šå…³é—­æ•´ä¸ªcontextï¼ˆåŒ…æ‹¬æ‰€æœ‰é¡µé¢ï¼‰
            await self.cleanup()
        
        return articles
    
    async def extract_article_data_robust(self, element, zipcode: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨Patchç‰¹å®šçš„é€‰æ‹©å™¨æå–æ–‡ç« æ•°æ®
        ä¼˜å…ˆä½¿ç”¨Patchæ¡†æ¶çš„ç²¾ç¡®é€‰æ‹©å™¨ï¼Œå¤±è´¥åå›é€€åˆ°é€šç”¨fallback
        
        Args:
            element: æ–‡ç« å…ƒç´ 
            zipcode: é‚®æ”¿ç¼–ç 
            
        Returns:
            æ–‡ç« æ•°æ®å­—å…¸
        """
        try:
            # æ ‡é¢˜ - ä¼˜å…ˆä½¿ç”¨Patchç‰¹å®šé€‰æ‹©å™¨
            title = await self.find_element_with_fallback(
                element,
                [
                    "h2.styles_Card__Title__cEqF8 a",  # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæ ‡é¢˜é“¾æ¥ï¼‰
                    "h2.styles_Card__Title__cEqF8",    # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæ ‡é¢˜æ–‡æœ¬ï¼‰
                    "h1", "h2", "h3", "h4",           # é€šç”¨fallback
                    ".title", ".headline", ".article-title", ".post-title",
                    "[data-testid*='title']",
                    "a[href] > *:first-child",
                    "a.title", "a.headline"
                ]
            )
            
            # é“¾æ¥ - ä¼˜å…ˆä½¿ç”¨Patchç‰¹å®šé€‰æ‹©å™¨
            link_elem = await self.find_element_with_fallback(
                element,
                [
                    "a.styles_Card__TitleLink__Df5jx",  # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæ ‡é¢˜é“¾æ¥ï¼‰
                    "h2.styles_Card__Title__cEqF8 a",  # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæ ‡é¢˜ä¸­çš„é“¾æ¥ï¼‰
                    "a[href]",                          # é€šç”¨é“¾æ¥
                    "a.article-link",
                    "a[href*='/news']",
                    "a[href*='/article']",
                    "a[href*='/story']",
                    ".title a",
                    ".headline a"
                ],
                extract_text=False
            )
            
            url = ""
            if link_elem:
                href = await link_elem.get_attribute("href")
                if href:
                    url = href
            
            # æ—¥æœŸ - ä¼˜å…ˆä½¿ç”¨Patchç‰¹å®šé€‰æ‹©å™¨
            date_elem = await self.find_element_with_fallback(
                element,
                [
                    "time[datetime]",                              # datetimeå±æ€§ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                    ".styles_Card__LabelWrapper__e_6qr time",       # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæ ‡ç­¾åŒ…è£…å™¨ä¸­çš„timeï¼‰
                    "time",
                    ".date", ".publish-date", ".published-date",
                    "[datetime]",
                    ".timestamp",
                    "[data-testid*='date']",
                    ".meta time",
                    ".byline time"
                ],
                extract_text=False
            )
            
            publish_date = None
            if date_elem:
                datetime_attr = await date_elem.get_attribute("datetime")
                if datetime_attr:
                    publish_date = datetime_attr
                else:
                    date_text = await date_elem.inner_text()
                    if date_text:
                        publish_date = date_text.strip()
            
            # æ‘˜è¦ - ä¼˜å…ˆä½¿ç”¨Patchç‰¹å®šé€‰æ‹©å™¨
            summary = await self.find_element_with_fallback(
                element,
                [
                    "p.styles_Card__Description__kWZTu",  # Patchç‰¹å®šé€‰æ‹©å™¨ï¼ˆæè¿°æ®µè½ï¼‰
                    ".summary", ".excerpt", ".description",
                    ".article-summary", ".post-excerpt",
                    "p:not(.title):not(.headline)",
                    ".snippet", ".preview"
                ]
            )
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if not title or not url:
                # å¦‚æœç‰¹å®šé€‰æ‹©å™¨å¤±è´¥ï¼Œå›é€€åˆ°é€šç”¨æ–¹æ³•
                logger.debug("Patchç‰¹å®šé€‰æ‹©å™¨å¤±è´¥ï¼Œå›é€€åˆ°é€šç”¨fallback")
                return await super().extract_article_data_robust(element, zipcode)
            
            return {
                "title": title,
                "url": url,
                "publish_date": publish_date or "",
                "content": summary or "",
                "content_summary": summary or "",
                "keywords": [],
                "zipcode": zipcode if zipcode else None
            }
            
        except Exception as e:
            logger.warning(f"Patchç‰¹å®šé€‰æ‹©å™¨æå–å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°é€šç”¨æ–¹æ³•")
            return await super().extract_article_data_robust(element, zipcode)
    
    async def _extract_article_data(self, element, zipcode: str) -> Dict[str, Any]:
        """
        ä»æ–‡ç« å…ƒç´ ä¸­æå–æ•°æ®ï¼ˆä½¿ç”¨å¥å£®çš„å¤šé€‰æ‹©å™¨æœºåˆ¶ï¼‰
        
        Args:
            element: Playwrightå…ƒç´ 
            zipcode: Zipcode
            
        Returns:
            æ–‡ç« æ•°æ®å­—å…¸
        """
        try:
            # ä½¿ç”¨robust mixinæå–æ•°æ®ï¼ˆä¼šè°ƒç”¨é‡å†™çš„extract_article_data_robustï¼‰
            article_data = await self.extract_article_data_robust(element, zipcode)
            
            if not article_data:
                return None
            
            # å¤„ç†URLï¼ˆç›¸å¯¹URLè½¬æ¢ä¸ºç»å¯¹URLï¼‰
            url = article_data.get('url', '')
            if url and not url.startswith('http'):
                url = f"https://patch.com{url}" if url.startswith('/') else f"https://patch.com/{url}"
                if self.debug_mode:
                    logger.debug(f"URLå·²è½¬æ¢ä¸ºç»å¯¹URL: {url}")
            
            # è§£ææ—¥æœŸï¼ˆä¼˜å…ˆä½¿ç”¨datetimeå±æ€§ï¼Œç„¶åæ˜¯æ–‡æœ¬å†…å®¹ï¼‰
            publish_date = article_data.get('publish_date', '')
            if publish_date:
                # å¦‚æœå·²ç»æ˜¯ISOæ ¼å¼ï¼ˆä»datetimeå±æ€§è·å–ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
                if 'T' in publish_date and ('Z' in publish_date or '+' in publish_date or '-' in publish_date[-6:]):
                    # å·²ç»æ˜¯ISOæ ¼å¼
                    parsed_date = publish_date
                else:
                    # éœ€è¦è§£æç›¸å¯¹æ—¶é—´æˆ–æ–‡æœ¬æ—¥æœŸ
                    parsed_date = self._parse_date(publish_date)
                if self.debug_mode:
                    logger.debug(f"æ—¥æœŸè§£æ: {publish_date} -> {parsed_date}")
                publish_date = parsed_date
            else:
                publish_date = datetime.utcnow().isoformat()
                if self.debug_mode:
                    logger.debug(f"æœªæ‰¾åˆ°æ—¥æœŸï¼Œä½¿ç”¨å½“å‰æ—¶é—´: {publish_date}")
            
            return {
                "source": self.source_name,
                "zipcode": zipcode,
                "title": article_data.get('title', ''),
                "url": url,
                "publish_date": publish_date,
                "content": article_data.get('content', ''),
                "content_summary": article_data.get('content_summary', ''),
                "keywords": article_data.get('keywords', [])
            }
            
        except Exception as e:
            logger.warning(f"æå–æ–‡ç« æ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def _parse_date(self, date_str: str) -> str:
        """
        è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºISOæ ¼å¼
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            
        Returns:
            ISOæ ¼å¼æ—¥æœŸå­—ç¬¦ä¸²
        """
        if not date_str:
            return datetime.utcnow().isoformat()
        
        date_str = date_str.strip().lower()
        now = datetime.utcnow()
        
        # å¤„ç†ç›¸å¯¹æ—¶é—´ï¼ˆä¸NewsbreakScraperç›¸åŒçš„é€»è¾‘ï¼‰
        if "just now" in date_str or "now" in date_str:
            return now.isoformat()
        elif "minute" in date_str:
            # ä¼˜åŒ–ï¼šç¼“å­˜re.searchç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨
            match = re.search(r'(\d+)', date_str)
            minutes = int(match.group(1)) if match else 0
            return (now - timedelta(minutes=minutes)).isoformat()
        elif "hour" in date_str:
            # ä¼˜åŒ–ï¼šç¼“å­˜re.searchç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨
            match = re.search(r'(\d+)', date_str)
            hours = int(match.group(1)) if match else 0
            return (now - timedelta(hours=hours)).isoformat()
        elif "day" in date_str or "yesterday" in date_str:
            # ä¼˜åŒ–ï¼šç¼“å­˜re.searchç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨
            days = 1 if "yesterday" in date_str else (int((match := re.search(r'(\d+)', date_str)).group(1)) if match else 1)
            return (now - timedelta(days=days)).isoformat()
        else:
            try:
                from dateutil import parser
                parsed_date = parser.parse(date_str)
                return parsed_date.isoformat()
            except Exception as e:
                logger.debug(f"æ—¥æœŸè§£æå¤±è´¥: {date_str} - {str(e)}")
                return now.isoformat()
